{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "# Load FER2013 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root='./dataset/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root='./dataset/test', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedforwardSNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(FeedforwardSNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(48 * 48, 512)    # First fully connected layer\n",
    "        # Leaky integrate-and-fire layer for spiking\n",
    "        self.lif1 = snn.Leaky(beta=0.9)\n",
    "        self.fc2 = nn.Linear(512, 256)        # Second fully connected layer\n",
    "        self.lif2 = snn.Leaky(beta=0.9)\n",
    "        self.fc3 = nn.Linear(256, 128)  # Output layer\n",
    "        self.lif3 = snn.Leaky(beta=0.9)\n",
    "        self.fc4 = nn.Linear(128, num_classes)  # Output layer\n",
    "        self.lif4 = snn.Leaky(beta=0.9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input image\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "        # print(x.size())\n",
    "        # Layer 1 with spiking\n",
    "        cur1 = self.fc1(x)\n",
    "        spk1, mem1 = self.lif1(cur1, mem1)\n",
    "        # print(spk1.size())\n",
    "        # Layer 2 with spiking\n",
    "        cur2 = self.fc2(spk1)\n",
    "        spk2, mem2 = self.lif2(cur2, mem2)\n",
    "        # print(spk2.size())\n",
    "        cur3 = self.fc3(spk2)\n",
    "        spk3, mem3 = self.lif3(cur3, mem3)\n",
    "        \n",
    "        out = self.fc4(spk3)\n",
    "        # print(spk3.size())\n",
    "\n",
    "        return out\n",
    "net = FeedforwardSNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.9062\n",
      "Epoch [2/20], Loss: 1.8204\n",
      "Epoch [3/20], Loss: 1.7699\n",
      "Epoch [4/20], Loss: 1.7326\n",
      "Epoch [5/20], Loss: 1.7021\n",
      "Epoch [6/20], Loss: 1.6775\n",
      "Epoch [7/20], Loss: 1.6519\n",
      "Epoch [8/20], Loss: 1.6233\n",
      "Epoch [9/20], Loss: 1.6088\n",
      "Epoch [10/20], Loss: 1.5789\n",
      "Epoch [11/20], Loss: 1.5649\n",
      "Epoch [12/20], Loss: 1.5344\n",
      "Epoch [13/20], Loss: 1.5146\n",
      "Epoch [14/20], Loss: 1.5126\n",
      "Epoch [15/20], Loss: 1.4868\n",
      "Epoch [16/20], Loss: 1.4797\n",
      "Epoch [17/20], Loss: 1.4444\n",
      "Epoch [18/20], Loss: 1.4556\n",
      "Epoch [19/20], Loss: 1.4392\n",
      "Epoch [20/20], Loss: 1.4247\n"
     ]
    }
   ],
   "source": [
    "train_class_counts = {3: 7215, 4: 4965,\n",
    "                      5: 4830, 2: 4097, 0: 3995, 6: 3171, 1: 436}\n",
    "class_weights = torch.tensor([1 / train_class_counts[i]\n",
    "                             for i in range(7)]).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "num_epochs = 20\n",
    "num_steps = 100\n",
    "# Training loop\n",
    "\n",
    "\n",
    "def train_snn(num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        running_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.long()\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            spk_rec = net(images)\n",
    "            # spk_rec= forward_pass(net, num_steps, data)\n",
    "            # print(spk_rec.size(),epoch)\n",
    "            # spk_rec.squeeze(1)\n",
    "            # labels = labels.view(-1)\n",
    "            # print(spk_rec.size())\n",
    "            loss = loss_fn(spk_rec, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(\n",
    "            f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "\n",
    "train_snn(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 38.44%\n"
     ]
    }
   ],
   "source": [
    "val_losses = []\n",
    "def evaluate():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "            # val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    \n",
    "    # val_loss /= len(test_loader)\n",
    "    # val_losses.append(val_loss)\n",
    "    # val_accuracy = 100 * correct / total\n",
    "\n",
    "\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'ffsnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Counts: Counter({3: 7215, 4: 4965, 5: 4830, 2: 4097, 0: 3995, 6: 3171, 1: 436})\n",
      "Testing Class Counts: Counter({3: 1774, 5: 1247, 4: 1233, 2: 1024, 0: 958, 6: 831, 1: 111})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "test_labels = [label for _, label in test_dataset]\n",
    "\n",
    "# Count the occurrences of each class label\n",
    "train_class_counts = Counter(train_labels)\n",
    "test_class_counts = Counter(test_labels)\n",
    "\n",
    "# Print the counts\n",
    "print(\"Training Class Counts:\", train_class_counts)\n",
    "print(\"Testing Class Counts:\", test_class_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
